{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2 \n",
    "import math\n",
    "#\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Activation\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.utils import multi_gpu_model\n",
    "#\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import warnings\n",
    "from os.path import split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "      <th>imagepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00022e1a.jpg</td>\n",
       "      <td>w_e15442c</td>\n",
       "      <td>/media/fanglab/DATA/Wei-Tse/Whale_Classifier/t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000466c4.jpg</td>\n",
       "      <td>w_1287fbc</td>\n",
       "      <td>/media/fanglab/DATA/Wei-Tse/Whale_Classifier/t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00087b01.jpg</td>\n",
       "      <td>w_da2efe0</td>\n",
       "      <td>/media/fanglab/DATA/Wei-Tse/Whale_Classifier/t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001296d5.jpg</td>\n",
       "      <td>w_19e5482</td>\n",
       "      <td>/media/fanglab/DATA/Wei-Tse/Whale_Classifier/t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0014cfdf.jpg</td>\n",
       "      <td>w_f22f3e3</td>\n",
       "      <td>/media/fanglab/DATA/Wei-Tse/Whale_Classifier/t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Image         Id                                          imagepath\n",
       "0  00022e1a.jpg  w_e15442c  /media/fanglab/DATA/Wei-Tse/Whale_Classifier/t...\n",
       "1  000466c4.jpg  w_1287fbc  /media/fanglab/DATA/Wei-Tse/Whale_Classifier/t...\n",
       "2  00087b01.jpg  w_da2efe0  /media/fanglab/DATA/Wei-Tse/Whale_Classifier/t...\n",
       "3  001296d5.jpg  w_19e5482  /media/fanglab/DATA/Wei-Tse/Whale_Classifier/t...\n",
       "4  0014cfdf.jpg  w_f22f3e3  /media/fanglab/DATA/Wei-Tse/Whale_Classifier/t..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reference: https://www.kaggle.com/gimunu/data-augmentation-with-keras-into-cnn\n",
    "# Load images\n",
    "train_images = os.listdir(\"/media/fanglab/DATA/Wei-Tse/Whale_Classifier/train/\")\n",
    "test_images = os.listdir(\"/media/fanglab/DATA/Wei-Tse/Whale_Classifier/test/\")\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "# Build Table\n",
    "df[\"imagepath\"] = df[\"Image\"].map( lambda x : \"/media/fanglab/DATA/Wei-Tse/Whale_Classifier/train/\"+x)\n",
    "ImageToLabelDict = dict( zip( df.Image, df[\"Id\"]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for category in os.listdir('CNN_TransferL/train/'):\n",
    "    if not os.path.isdir('CNN_TransferL/dev/'+category):\n",
    "        os.mkdir('CNN_TransferL/dev/'+category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# After I submitted to Kaggle,I found my model has high varaince\n",
    "# So I retrained the model \n",
    "# At this time, I split the data into train and dev set\n",
    "#I only split the data that have more than 20 images\n",
    "for category in os.listdir('CNN_TransferL/train/'):\n",
    "    file=os.listdir('CNN_TransferL/train/'+category)\n",
    "    if len(file)<20:\n",
    "        continue\n",
    "    elif len(file)<35:\n",
    "        if not os.path.isdir('CNN_TransferL/dev/'+category):\n",
    "            os.mkdir('CNN_TransferL/dev/'+category)\n",
    "        shutil.move('CNN_TransferL/train/'+category+'/'+file[0],'CNN_TransferL/dev/'+category+'/'+file[0])\n",
    "    elif len(file)<=810:\n",
    "        if not os.path.isdir('CNN_TransferL/dev/'+category):\n",
    "            os.mkdir('CNN_TransferL/dev/'+category)\n",
    "        for i in range(0,93):\n",
    "            shutil.move('CNN_TransferL/train/'+category+'/'+file[i],'CNN_TransferL/dev/'+category+'/'+file[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9745 images belonging to 4251 classes.\n",
      "Found 105 images belonging to 4251 classes.\n"
     ]
    }
   ],
   "source": [
    "# Build CNN imagedatabase\n",
    "\n",
    "batch_size = 64\n",
    "seednum = 1\n",
    "\n",
    "#generator for training\n",
    "# the folder name will be though as label name if class_mode=\"categorical\"\n",
    "# And keras will use folder name for one hot encoding\n",
    "# let's why alphabery order is important\n",
    "\n",
    "\n",
    "# Data Augmentation\n",
    "train_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=.15,\n",
    "    height_shift_range=.15,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "#data from specific path\n",
    "trainD = train_gen.flow_from_directory(\n",
    "        'CNN_TransferL/train/',\n",
    "        class_mode=\"categorical\",\n",
    "        batch_size=batch_size,\n",
    "        target_size=(224, 224),\n",
    "        seed=seednum,\n",
    "        shuffle=False)\n",
    "\n",
    "# Data Augmentation\n",
    "dev_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=.15,\n",
    "    height_shift_range=.15,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "#data from specific path\n",
    "devD = dev_gen.flow_from_directory(\n",
    "        'CNN_TransferL/dev/',\n",
    "        class_mode=\"categorical\",\n",
    "        batch_size=batch_size,\n",
    "        target_size=(224, 224),\n",
    "        seed=seednum,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Got One-hot encoding in keras\n",
    "encoded_dict=trainD.class_indices\n",
    "# Inverse encoded : labelname\n",
    "dict_encodedlabel={a :b for b,a in encoded_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LabelEncoder + OnehotEncoder\n",
    "class LabelOneHotEncoder():\n",
    "    def __init__(self):\n",
    "        self.ohe = OneHotEncoder()\n",
    "        self.le = LabelEncoder()\n",
    "    def fit_transform(self, x):\n",
    "        features = self.le.fit_transform( x)\n",
    "        return self.ohe.fit_transform( features.reshape(-1,1))\n",
    "    def transform( self, x):\n",
    "        return self.ohe.transform( self.la.transform( x.reshape(-1,1)))\n",
    "    def inverse_tranform( self, x):\n",
    "        return self.le.inverse_transform( self.ohe.inverse_tranform( x))\n",
    "    def inverse_labels( self, x):\n",
    "        return self.le.inverse_transform( x)\n",
    "#constructing class weights\n",
    "WeightFunction = lambda x : 1./x**0.75\n",
    "ClassLabel2Index = lambda x : lohe.le.inverse_tranform([[x]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keras use alphabery order for one-hot enciding\n",
    "# Sklearn also use alphabery order for one-hot enciding\n",
    "# So, I guess my weighting order can match the order in imageDataGenrator.flow_from_dictionary\n",
    "lohe = LabelOneHotEncoder()\n",
    "# find the label name\n",
    "y = list(map(ImageToLabelDict.get, train_images))\n",
    "# Encode label\n",
    "y_cat = lohe.fit_transform(y)\n",
    "#\n",
    "CountDict = dict( df[\"Id\"].value_counts())\n",
    "# set the weighting dictionary \n",
    "class_weight_dic = {lohe.le.transform( [image_name])[0]:WeightFunction(count) for image_name, count in CountDict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train new model with Resnet50\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "# Import Resnet \n",
    "ResNet50model = ResNet50(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract features from flatten_6 layer\n",
    "# Add to new FC layer \n",
    "x = Dense(4096, activation='relu')(ResNet50model.get_layer('flatten_2').output)\n",
    "# Final Output Layer 4251 is # of categories\n",
    "predictions = Dense(4251, activation='softmax')(x)\n",
    "# Connect all layers\n",
    "ResNet50model_TL=Model(inputs=ResNet50model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transfer learning only update FC layers\n",
    "for layerG in ResNet50model_TL.layers[:176]:\n",
    "   layerG.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# optimizer \n",
    "ot=keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.95, amsgrad=False)\n",
    "#Set model trained with 2 gpus \n",
    "ResNet50model_TL = multi_gpu_model(ResNet50model_TL, gpus=2)\n",
    "#Compile the model\n",
    "ResNet50model_TL.compile(optimizer=ot, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(monitor='val_acc', min_delta=0.0001, patience=5, \\\n",
    "                          verbose=1, mode='auto')\n",
    "callbacks_list = [earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "epochsnum = 20\n",
    "ResNet50model_TL.fit_generator(trainD,\n",
    "          steps_per_epoch=9745//batch_size,\n",
    "          epochs=epochsnum,\n",
    "          verbose=1,\n",
    "          class_weight=class_weight_dic,\n",
    "          shuffle=False,\n",
    "          validation_steps=105//batch_size,\n",
    "          validation_data=devD, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import VGG19\n",
    "from keras.applications.vgg19 import VGG19\n",
    "vggorigin = VGG19(weights='imagenet', include_top=True)\n",
    "predictions = Dense(4251, activation='softmax')(vggorigin.get_layer('fc2').output)\n",
    "VGG_TL=Model(inputs=vggorigin.input, outputs=predictions)\n",
    "# transfer learning only update FC layers\n",
    "for layerG in VGG_TL.layers[:24]:\n",
    "   layerG.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# optimizer \n",
    "ot=keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.95, amsgrad=False)\n",
    "#Set model trained with 2 gpus \n",
    "VGG_TL = multi_gpu_model(VGG_TL, gpus=2)\n",
    "#Compile the model\n",
    "VGG_TL.compile(optimizer=ot, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(monitor='val_acc', min_delta=0.0001, patience=5, \\\n",
    "                          verbose=1, mode='auto')\n",
    "callbacks_list = [earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "139/152 [==========================>...] - ETA: 10s - loss: 8.0203 - acc: 0.0733"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "epochsnum = 20\n",
    "VGG_TL.fit_generator(trainD,\n",
    "          steps_per_epoch=9745//batch_size,\n",
    "          epochs=epochsnum,\n",
    "          verbose=1,\n",
    "          class_weight=class_weight_dic,\n",
    "          shuffle=False,\n",
    "          validation_steps=105//batch_size,\n",
    "          validation_data=devD, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
